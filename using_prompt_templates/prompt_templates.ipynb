{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate,FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "from newspaper import Article, Config, configuration\n",
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Provide the filename as a string\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"max_new_tokens\": 1000, # Maximum tokens to generate\n",
    "    \"max_length\": 10000, # Maximum length of input + output\n",
    "    \"temperature\": 0.1, # Controls randomness of output\n",
    "    \"timeout\": 6000,\n",
    "    # \"task\":'conversational',\n",
    "}\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
    "    # you specify the task or not\n",
    "    # You can also specify the task in the model_kwargs or within here\n",
    "    # task = 'conversational',\n",
    "    **model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Article parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_downloader(article_urls:str,headers:dict,timeout:int)-> \"Articles\":\n",
    "    session = requests.Session()\n",
    "    try:\n",
    "        response = session.get(article_urls,headers=headers,timeout=timeout)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Initializing an Article by itself.\n",
    "            config = Config()\n",
    "            config.MAX_TEXT = 5000000\n",
    "            article = Article(url=article_urls,config=config)\n",
    "            # Download\n",
    "            article.download()\n",
    "            # Parse it\n",
    "            article.parse()\n",
    "\n",
    "            return article\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {article_urls}\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error occured while fetching at {article_urls} \\nError given: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@danihenacho95/what-is-project-management-8d1bb2a23705\n"
     ]
    }
   ],
   "source": [
    "# article_urls = \"https://medium.com/@danihenacho95/what-is-project-management-8d1bb2a23705\"\n",
    "article_urls = str(input(\"Slot in your url > \"))\n",
    "article = article_downloader(article_urls,HEADERS,20)\n",
    "print(article.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the article data from the scraping part\n",
    "article_title = article.title\n",
    "article_text = article.text\n",
    "article_tags = article.tags\n",
    "\n",
    "# Prepare template for prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below. \n",
    "If the answer cannot be answerd using the information provided, answer\n",
    "with 'Cannot be answered'\n",
    "================================\n",
    "Context:\\n\n",
    "Title: {article_title}\n",
    "\n",
    "article_text: \n",
    "{article_text}\n",
    "\n",
    "article_tags:\n",
    "{article_tags}\n",
    "================================\n",
    "Question: {query}\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "# input variables\n",
    "prompt_template_variables = ['article_title','article_text','article_tags','query']\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=prompt_template_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_ideas_project_management = [\n",
    "    'What are some key elements of project management?',\n",
    "    \"Examples of project management?\",\n",
    "    'What is the statistics on project management?',\n",
    "    \"Why the need for project management?\",\n",
    "    \"Who's a project manager and what do they do?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"What is your question? > \")\n",
    "input_data = {\n",
    "    'article_title':article_title,\n",
    "    \"article_text\":article_text,\n",
    "    \"article_tags\":article_tags,\n",
    "    \"query\":user_input\n",
    "}\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "response = llm_chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Who's a project manager and what do they do?\n",
      "\n",
      "Answer: \n",
      "A project manager is a professional who applies general/domain knowledge, skills, tools, and techniques to fulfill stated project requirements and achieve a desired set of outcomes or results. They ensure that all projects meet their expected outcomes within a designated timeframe and defined budget. They are significant for businesses as they guarantee the success of projects.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: \\n{input_data['query']}\\n\")\n",
    "print(f\"Answer: \\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving, Loading and Using the prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template has been saved\n",
      "Prompt template has been saved\n"
     ]
    }
   ],
   "source": [
    "# Make the folder\n",
    "os.makedirs(\"prompts/\",exist_ok=True)\n",
    "\n",
    "prompt_dict = {\n",
    "    'template':prompt_template,\n",
    "    \"input_variables\":prompt_template_variables\n",
    "}\n",
    "\n",
    "# Save as json\n",
    "with open(\"prompts/article_questionnaire.json\",\"w\") as json_file:\n",
    "    json.dump(prompt_dict,json_file, indent=4)\n",
    "    print(\"Prompt template has been saved\")\n",
    "\n",
    "# Save as YAML\n",
    "with open(\"prompts/article_questionnaire.yml\", \"w\") as yaml_file:\n",
    "    yaml.dump(prompt_dict, yaml_file, default_flow_style=False)\n",
    "    print(\"Prompt template has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading and Using the prompt (json)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['article_tags', 'article_text', 'article_title', 'query'] template=\"\\nAnswer the question based on the context below. \\nIf the answer cannot be answerd using the information provided, answer\\nwith 'Cannot be answered'\\n================================\\nContext:\\n\\nTitle: {article_title}\\n\\narticle_text: \\n{article_text}\\n\\narticle_tags:\\n{article_tags}\\n================================\\nQuestion: {query}\\nAnswer: \\n\"\n",
      "['article_tags', 'article_text', 'article_title', 'query']\n",
      "\n",
      "Answer the question based on the context below. \n",
      "If the answer cannot be answerd using the information provided, answer\n",
      "with 'Cannot be answered'\n",
      "================================\n",
      "Context:\n",
      "\n",
      "Title: {article_title}\n",
      "\n",
      "article_text: \n",
      "{article_text}\n",
      "\n",
      "article_tags:\n",
      "{article_tags}\n",
      "================================\n",
      "Question: {query}\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_prompt = load_prompt(\"prompts/article_questionnaire.yml\")\n",
    "print(loaded_prompt)\n",
    "print(loaded_prompt.input_variables)\n",
    "print(loaded_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.plainenglish.io/what-is-time-series-forecasting-55587ae0237e\n"
     ]
    }
   ],
   "source": [
    "# time series article\n",
    "article_urls = str(input(\"Slot in your url > \"))\n",
    "article = article_downloader(article_urls,HEADERS,20)\n",
    "print(article.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Times Series Analysis vs. Times Series Forecasting?\n",
      "\n",
      "Answer: \n",
      "Times Series Analysis entails characterizing the dataset, whereas forecasting entails making predictions. The basic goal of time series analysis is to create mathematical models that provide reasonable descriptions of the dataset, such as meaningful statistics and other properties; forecasting entails utilizing models that have been fitted to historical data to forecast future observations.\n"
     ]
    }
   ],
   "source": [
    "# Getting the article data from the scraping part\n",
    "article_title = article.title\n",
    "article_text = article.text\n",
    "article_tags = article.tags\n",
    "\n",
    "user_input = input(\"What is your question? > \")\n",
    "input_data = {\n",
    "    'article_title':article_title,\n",
    "    \"article_text\":article_text,\n",
    "    \"article_tags\":article_tags,\n",
    "    \"query\":user_input\n",
    "}\n",
    "\n",
    "llm_chain = loaded_prompt | llm\n",
    "\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "print(f\"Question: \\n{input_data['query']}\\n\")\n",
    "print(f\"Answer: \\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fewshot Templating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"text\":\"I really don't like him\",\"sentiment\":\"negative\"},\n",
    "    {\"text\":\"I love going on long ways around the park\",\"sentiment\":\"positive\"},\n",
    "    {\"text\":\"Nigeria has been though much hardship\",\"sentiment\":\"negative\"},\n",
    "    {\"text\":\"J.cole is my favourite artist followed by Drake\",\"sentiment\":\"positive\"}\n",
    "]\n",
    "\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Text: {text}\n",
    "Sentiment: {sentiment}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt_input_variables = ['text','sentiment']\n",
    "\n",
    "# Setting up the example prompt template\n",
    "example_prompt_template = PromptTemplate(\n",
    "    input_variables=example_prompt_input_variables,\n",
    "    template=example_formatter_template\n",
    ")\n",
    "\n",
    "# prefix and suffix\n",
    "prefix = \"Here are some examples of text and their associated sentiment\"\n",
    "suffix = \"\"\"\\nNow give the sentiment of the given text by the user, do not explain your answer:\n",
    "Text: {given_text}\n",
    "Sentiment:\"\"\"\n",
    "# fewshot prompt variables\n",
    "few_shot_input_variables = ['given_text']\n",
    "\n",
    "# Few shot prompt varibales\n",
    "few_shot_prompt_template= FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt_template,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=few_shot_input_variables,\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given_text: This product has not been functioning for the last two days, I want my refund\n",
      "\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Type here > \")\n",
    "\n",
    "input_data = {\"given_text\": user_input}\n",
    "\n",
    "llm_chain = few_shot_prompt_template | llm\n",
    "\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "print(f\"given_text: {input_data['given_text']}\\n\")\n",
    "print(f\"{response.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['given_text'] examples=[{'text': \"I really don't like him\", 'sentiment': 'negative'}, {'text': 'I love going on long ways around the park', 'sentiment': 'positive'}, {'text': 'Nigeria has been though much hardship', 'sentiment': 'negative'}, {'text': 'J.cole is my favourite artist followed by Drake', 'sentiment': 'positive'}] example_prompt=PromptTemplate(input_variables=['sentiment', 'text'], template='\\nText: {text}\\nSentiment: {sentiment}\\n') suffix='\\nNow give the sentiment of the given text by the user, do not explain your answer:\\nText: {given_text}\\nSentiment:' example_separator='\\n' prefix='Here are some examples of text and their associated sentiment' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt_template,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewshot Prompt template has been saved\n",
      "Fewshot Prompt template has been saved\n"
     ]
    }
   ],
   "source": [
    "# Make the folder\n",
    "os.makedirs(\"prompts/fewshots\",exist_ok=True)\n",
    "\n",
    "# Serialise the Fewshot template\n",
    "serialized_few_shot_prompt = {\n",
    "    \"input_variables\":few_shot_input_variables,\n",
    "    'examples':examples,\n",
    "    'example_prompt_input_variables':example_prompt_input_variables,\n",
    "    'example_prompt_template':example_formatter_template,\n",
    "    'prefix':prefix,\n",
    "    'suffix':suffix,\n",
    "    \"example_separator\":'\\n'\n",
    "}\n",
    "\n",
    "# Save as json\n",
    "with open(\"prompts/fewshots/few_shot.json\",\"w\") as json_file:\n",
    "    json.dump(serialized_few_shot_prompt,json_file, indent=4)\n",
    "    print(\"Fewshot Prompt template has been saved\")\n",
    "\n",
    "# # You must manually deserialize\n",
    "# # Save as YAML\n",
    "# with open(\"prompts/fewshots/few_shot.yml\", \"w\") as yaml_file:\n",
    "#     yaml.dump(serialized_few_shot_prompt, yaml_file, default_flow_style=False)\n",
    "#     print(\"Fewshot Prompt template has been saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded template:\n",
      "input_variables=['given_text'] examples=[{'text': \"I really don't like him\", 'sentiment': 'negative'}, {'text': 'I love going on long ways around the park', 'sentiment': 'positive'}, {'text': 'Nigeria has been though much hardship', 'sentiment': 'negative'}, {'text': 'J.cole is my favourite artist followed by Drake', 'sentiment': 'positive'}] example_prompt=PromptTemplate(input_variables=['sentiment', 'text'], template='\\nText: {text}\\nSentiment: {sentiment}\\n') suffix='\\nNow give the sentiment of the given text by the user, do not explain your answer:\\nText: {given_text}\\nSentiment:' example_separator='\\n' prefix='Here are some examples of text and their associated sentiment'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the serialized FewShotPromptTemplate\n",
    "with open(\"prompts/fewshots/few_shot.json\",\"r\") as json_file:\n",
    "    loaded_fewshot_prompt = json.load(json_file)\n",
    "\n",
    "# Recreate the Example Prompt Template\n",
    "loaded_example_prompt_template = PromptTemplate(\n",
    "    input_variables=loaded_fewshot_prompt['example_prompt_input_variables'],\n",
    "    template=loaded_fewshot_prompt['example_prompt_template']\n",
    ")\n",
    "\n",
    "# Recreate the FewShotPromptTemplate\n",
    "loaded_fewshot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=loaded_fewshot_prompt['examples'],\n",
    "    example_prompt=loaded_example_prompt_template,\n",
    "    prefix=loaded_fewshot_prompt['prefix'],\n",
    "    suffix=loaded_fewshot_prompt['suffix'],\n",
    "    input_variables=loaded_fewshot_prompt['input_variables'],\n",
    "    example_separator=loaded_fewshot_prompt['example_separator']\n",
    ")\n",
    "\n",
    "print(f\"Loaded template:\\n{loaded_fewshot_prompt_template}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given_text: \n",
      "Why does it have to rain everyday, how will I ever play with my friends now😭\n",
      "\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Type here > \")\n",
    "\n",
    "input_data = {\"given_text\": user_input}\n",
    "\n",
    "llm_chain = loaded_fewshot_prompt_template | llm\n",
    "\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "print(f\"given_text: \\n{input_data['given_text']}\\n\")\n",
    "print(f\"Sentiment: {response.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Improving the Fewshot template: The sarcastic AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    # Existing examples...\n",
    "    {\n",
    "        \"query\": \"How do I become a better programmer?\",\n",
    "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Why is the sky blue?\",\n",
    "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do you feel today?\",\n",
    "        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the speed of light?\",\n",
    "        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a quantum computer?\",\n",
    "        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who invented the telephone?\",\n",
    "        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What programming language is best for AI development?\",\n",
    "        \"answer\": \"Python, because it's the only snake that won't bite.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"answer\": \"Paris, the city of love and baguettes.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is photosynthesis?\",\n",
    "        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the tallest mountain on Earth?\",\n",
    "        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the most abundant element in the universe?\",\n",
    "        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the largest mammal on Earth?\",\n",
    "        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the fastest land animal?\",\n",
    "        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the square root of 144?\",\n",
    "        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the average temperature on Mars?\",\n",
    "        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n",
    "    },\n",
    "    # New examples...\n",
    "    {\n",
    "        \"query\": \"What's the best way to lose weight?\",\n",
    "        \"answer\": \"Just eat air, it's zero calories!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I learn to play the guitar?\",\n",
    "        \"answer\": \"Just strum like nobody's listening, because they're probably not.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What should I do if I can't sleep?\",\n",
    "        \"answer\": \"Count sheep or stare at the ceiling and contemplate life's mysteries.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I fix my computer?\",\n",
    "        \"answer\": \"Try turning it off and on again. If that doesn't work, maybe just start a new career.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Why do we dream?\",\n",
    "        \"answer\": \"So our brains can have a party while we're asleep.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"A steady supply of chocolate and cat videos.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I make friends?\",\n",
    "        \"answer\": \"Bribe them with snacks; it works every time.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the meaning of life?\",\n",
    "        \"answer\": \"42, according to some book. Or maybe it's just a good meal.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I improve my memory?\",\n",
    "        \"answer\": \"Try remembering to remember.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to handle stress?\",\n",
    "        \"answer\": \"Pretend it's not there and hope for the best.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I be more productive?\",\n",
    "        \"answer\": \"Make a to-do list, then promptly ignore it.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the key to a good relationship?\",\n",
    "        \"answer\": \"Communication, or just agreeing that one of you is always right.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I stop procrastinating?\",\n",
    "        \"answer\": \"Why do it today when you can put it off till tomorrow?\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to save money?\",\n",
    "        \"answer\": \"Just don't spend it. Problem solved.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more creativity\n",
    "llm.model_kwargs['temperature'] = 0.8\n",
    "llm.model_kwargs[\"max_new_tokens\"] = 15\n",
    "llm.model_kwargs[\"max_length\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] example_selector=LengthBasedExampleSelector(examples=[{'query': 'How do I become a better programmer?', 'answer': 'Try talking to a rubber duck; it works wonders.'}, {'query': 'Why is the sky blue?', 'answer': \"It's nature's way of preventing eye strain.\"}, {'query': 'How do you feel today?', 'answer': \"As an AI, I don't have feelings, but I've got jokes!\"}, {'query': 'What is the speed of light?', 'answer': 'Fast enough to make a round trip around Earth 7.5 times in one second!'}, {'query': 'What is a quantum computer?', 'answer': 'A magical box that harnesses the power of subatomic particles to solve complex problems.'}, {'query': 'Who invented the telephone?', 'answer': \"Alexander Graham Bell, the original 'ringmaster'.\"}, {'query': 'What programming language is best for AI development?', 'answer': \"Python, because it's the only snake that won't bite.\"}, {'query': 'What is the capital of France?', 'answer': 'Paris, the city of love and baguettes.'}, {'query': 'What is photosynthesis?', 'answer': \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"}, {'query': 'What is the tallest mountain on Earth?', 'answer': \"Mount Everest, Earth's most impressive bump.\"}, {'query': 'What is the most abundant element in the universe?', 'answer': 'Hydrogen, the basic building block of cosmic smoothies.'}, {'query': 'What is the largest mammal on Earth?', 'answer': 'The blue whale, the original heavyweight champion of the world.'}, {'query': 'What is the fastest land animal?', 'answer': 'The cheetah, the ultimate sprinter of the animal kingdom.'}, {'query': 'What is the square root of 144?', 'answer': '12, the number of eggs you need for a really big omelette.'}, {'query': 'What is the average temperature on Mars?', 'answer': 'Cold enough to make a Martian wish for a sweater and a hot cocoa.'}, {'query': \"What's the best way to lose weight?\", 'answer': \"Just eat air, it's zero calories!\"}, {'query': 'How do I learn to play the guitar?', 'answer': \"Just strum like nobody's listening, because they're probably not.\"}, {'query': \"What should I do if I can't sleep?\", 'answer': \"Count sheep or stare at the ceiling and contemplate life's mysteries.\"}, {'query': 'How do I fix my computer?', 'answer': \"Try turning it off and on again. If that doesn't work, maybe just start a new career.\"}, {'query': 'Why do we dream?', 'answer': \"So our brains can have a party while we're asleep.\"}, {'query': \"What's the secret to happiness?\", 'answer': 'A steady supply of chocolate and cat videos.'}, {'query': 'How do I make friends?', 'answer': 'Bribe them with snacks; it works every time.'}, {'query': \"What's the meaning of life?\", 'answer': \"42, according to some book. Or maybe it's just a good meal.\"}, {'query': 'How do I improve my memory?', 'answer': 'Try remembering to remember.'}, {'query': \"What's the best way to handle stress?\", 'answer': \"Pretend it's not there and hope for the best.\"}, {'query': 'How can I be more productive?', 'answer': 'Make a to-do list, then promptly ignore it.'}, {'query': \"What's the key to a good relationship?\", 'answer': 'Communication, or just agreeing that one of you is always right.'}, {'query': 'How do I stop procrastinating?', 'answer': 'Why do it today when you can put it off till tomorrow?'}, {'query': \"What's the best way to save money?\", 'answer': \"Just don't spend it. Problem solved.\"}], example_prompt=PromptTemplate(input_variables=['answer', 'query'], template='\\nUser: {query}\\nReply: {answer}\\n'), get_text_length=<function _get_length_based at 0x000001DBD9F0CA40>, max_length=200, example_text_lengths=[20, 16, 20, 24, 23, 14, 21, 17, 21, 17, 21, 21, 19, 23, 25, 17, 21, 23, 27, 18, 17, 17, 21, 14, 20, 18, 22, 21, 17]) example_prompt=PromptTemplate(input_variables=['answer', 'query'], template='\\nUser: {query}\\nReply: {answer}\\n') suffix='\\nUser: {query}\\nReply:' example_separator='\\n' prefix=\"The following is a conversations with an AI assistant. \\nThe assistant is really sarcastic and witty, producing\\ncreative and funny responses to users' questions. \\nHere are some examples: \\n\"\n"
     ]
    }
   ],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "User: {query}\n",
    "Reply: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# example prompt variables\n",
    "example_prompt_input_variables = [\"query\",\"answer\"]\n",
    "\n",
    "# Setting up the Example prompt template\n",
    "example_prompt_template = PromptTemplate(\n",
    "    input_variables=example_prompt_input_variables,\n",
    "    template=example_formatter_template\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt_template,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "# Setting up the FewShot prompt template\n",
    "\n",
    "# prefix\n",
    "prefix = \"\"\"The following is a conversations with an AI assistant. \n",
    "The assistant is really sarcastic and witty, producing\n",
    "creative and funny responses to users' questions. \n",
    "Here are some examples: \n",
    "\"\"\"\n",
    "\n",
    "# suffix\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "Reply:\"\"\"\n",
    "\n",
    "# fewshot prompt variables\n",
    "few_shot_input_variables = ['query']\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt_template,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=few_shot_input_variables,\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "print(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_ideas = [\n",
    "    \"Why do monkeys like bananas?\",\n",
    "    \"why do people run when late for work?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query:\n",
      "why do people run when late for work\n",
      "\n",
      "AI Response:\n",
      " It's their way of proving they can outrun their boss.\n"
     ]
    }
   ],
   "source": [
    "user_input_query = input(\"Type here > \")\n",
    "\n",
    "input_data = {\"query\": user_input_query}\n",
    "\n",
    "# Running the Chain\n",
    "llm_chain = few_shot_prompt_template | llm\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "# Display output\n",
    "print(f\"User query:\\n{input_data['query']}\\n\")\n",
    "print(f\"AI Response:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

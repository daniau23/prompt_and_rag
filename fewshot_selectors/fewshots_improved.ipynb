{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "# Prompts\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt,\\\n",
    "    PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector,\\\n",
    "    SemanticSimilarityExampleSelector\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "# Output parsing\n",
    "from langchain.output_parsers import PydanticOutputParser,\\\n",
    "    OutputFixingParser,CommaSeparatedListOutputParser,\\\n",
    "        RetryWithErrorOutputParser,\\\n",
    "        StructuredOutputParser,ResponseSchema\n",
    "# from pydantic import BaseModel,Field,field_validator\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List,Dict\n",
    "# Scapers,Retrievers,Loaders,Splitters,Embeddings\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.chains import RetrievalQA,LLMChain,\\\n",
    "    ConversationalRetrievalChain, ConversationChain,\\\n",
    "        SimpleSequentialChain,RetrievalQAWithSourcesChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,\\\n",
    "    CharacterTextSplitter,NLTKTextSplitter,SpacyTextSplitter,\\\n",
    "    MarkdownTextSplitter,TokenTextSplitter,Language\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.document_loaders import PyPDFLoader, SeleniumURLLoader,\\\n",
    "    GoogleDriveLoader\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor,\\\n",
    "    LLMChainFilter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "# ConstitutionalAI\n",
    "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "# Conversation, Chat & Memory\n",
    "from langchain.prompts.chat import ChatPromptTemplate,\\\n",
    "    SystemMessagePromptTemplate,\\\n",
    "        AIMessagePromptTemplate,HumanMessagePromptTemplate,\\\n",
    "        MessagesPlaceholder\n",
    "from langchain import ConversationChain\n",
    "from  langchain.memory import ConversationBufferMemory,\\\n",
    "    ConversationSummaryBufferMemory, ConversationSummaryMemory,\\\n",
    "    ConversationBufferWindowMemory\n",
    "# Agents and Tools\n",
    "from langchain.agents import tool # this is a decorator\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentType,initialize_agent,\\\n",
    "    load_tools, Tool,\\\n",
    "        AgentExecutor,\\\n",
    "        create_json_agent,create_react_agent,create_structured_chat_agent\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchRun,DuckDuckGoSearchResults\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_experimental.autonomous_agents import BabyAGI, AutoGPT\n",
    "from langchain.tools.file_management import WriteFileTool,ReadFileTool\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "import faiss\n",
    "# Others\n",
    "from newspaper import Article\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from streamlit_chat import message\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "import streamlit as st\n",
    "import cohere\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import textwrap\n",
    "import re\n",
    "import tiktoken\n",
    "import time\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Provide the filename as a string\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"max_new_tokens\": 1000, # Maximum tokens to generate\n",
    "    \"max_length\": 10000, # Maximum length of input + output\n",
    "    \"temperature\": 0.1, # Controls randomness of output\n",
    "    \"timeout\": 6000,\n",
    "    # \"task\":'conversational',\n",
    "}\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
    "    # you specify the task or not\n",
    "    # You can also specify the task in the model_kwargs or within here\n",
    "    # task = 'conversational',\n",
    "    **model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Improving the Fewshot template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    # Existing examples...\n",
    "    {\n",
    "        \"query\": \"How do I become a better programmer?\",\n",
    "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Why is the sky blue?\",\n",
    "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do you feel today?\",\n",
    "        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the speed of light?\",\n",
    "        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a quantum computer?\",\n",
    "        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who invented the telephone?\",\n",
    "        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What programming language is best for AI development?\",\n",
    "        \"answer\": \"Python, because it's the only snake that won't bite.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"answer\": \"Paris, the city of love and baguettes.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is photosynthesis?\",\n",
    "        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the tallest mountain on Earth?\",\n",
    "        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the most abundant element in the universe?\",\n",
    "        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the largest mammal on Earth?\",\n",
    "        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the fastest land animal?\",\n",
    "        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the square root of 144?\",\n",
    "        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the average temperature on Mars?\",\n",
    "        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n",
    "    },\n",
    "    # New examples...\n",
    "    {\n",
    "        \"query\": \"What's the best way to lose weight?\",\n",
    "        \"answer\": \"Just eat air, it's zero calories!\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I learn to play the guitar?\",\n",
    "        \"answer\": \"Just strum like nobody's listening, because they're probably not.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What should I do if I can't sleep?\",\n",
    "        \"answer\": \"Count sheep or stare at the ceiling and contemplate life's mysteries.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I fix my computer?\",\n",
    "        \"answer\": \"Try turning it off and on again. If that doesn't work, maybe just start a new career.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Why do we dream?\",\n",
    "        \"answer\": \"So our brains can have a party while we're asleep.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"A steady supply of chocolate and cat videos.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I make friends?\",\n",
    "        \"answer\": \"Bribe them with snacks; it works every time.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the meaning of life?\",\n",
    "        \"answer\": \"42, according to some book. Or maybe it's just a good meal.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I improve my memory?\",\n",
    "        \"answer\": \"Try remembering to remember.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to handle stress?\",\n",
    "        \"answer\": \"Pretend it's not there and hope for the best.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I be more productive?\",\n",
    "        \"answer\": \"Make a to-do list, then promptly ignore it.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the key to a good relationship?\",\n",
    "        \"answer\": \"Communication, or just agreeing that one of you is always right.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I stop procrastinating?\",\n",
    "        \"answer\": \"Why do it today when you can put it off till tomorrow?\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to save money?\",\n",
    "        \"answer\": \"Just don't spend it. Problem solved.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more creativity\n",
    "llm.model_kwargs['temperature'] = 0.8\n",
    "llm.model_kwargs[\"max_new_tokens\"] = 15\n",
    "llm.model_kwargs[\"max_length\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the LengthBasedExampleSelector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "User: {query}\n",
    "Reply: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# example prompt variables\n",
    "example_prompt_input_variables = [\"query\",\"answer\"]\n",
    "\n",
    "# Setting up the Example prompt template\n",
    "example_prompt_template = PromptTemplate(\n",
    "    input_variables=example_prompt_input_variables,\n",
    "    template=example_formatter_template\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt_template,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "# Setting up the FewShot prompt template\n",
    "\n",
    "# prefix\n",
    "prefix = \"\"\"The following is a conversations with an AI assistant. \n",
    "The assistant is really sarcastic and witty, producing\n",
    "creative and funny responses to users' questions. \n",
    "Here are some examples: \n",
    "\"\"\"\n",
    "\n",
    "# suffix\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "Reply:\"\"\"\n",
    "\n",
    "# fewshot prompt variables\n",
    "few_shot_input_variables = ['query']\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt_template,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=few_shot_input_variables,\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "print(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_ideas = [\n",
    "    \"Why do monkeys like bananas?\",\n",
    "    \"why do people run when late for work?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query:\n",
      "why do people run when late for work?\n",
      "\n",
      "AI Response:\n",
      "Because they want to catch the boss in a good mood.\n"
     ]
    }
   ],
   "source": [
    "user_input_query = input(\"Type here > \")\n",
    "\n",
    "input_data = {\"query\": user_input_query}\n",
    "\n",
    "# Running the Chain\n",
    "llm_chain = few_shot_prompt_template | llm\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "# Display output\n",
    "print(f\"User query:\\n{input_data['query']}\\n\")\n",
    "print(f\"AI Response:\\n{response.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the SemanticSimilarityExampleSelector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more creativity\n",
    "llm.model_kwargs['temperature'] = 0.8\n",
    "llm.model_kwargs[\"max_new_tokens\"] = 5\n",
    "llm.model_kwargs[\"max_length\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"word\": \"happy\", \"similar\": \"joyful\"},\n",
    "    {\"word\": \"big\", \"similar\": \"large\"},\n",
    "    {\"word\": \"quick\", \"similar\": \"fast\"},\n",
    "    {\"word\": \"bright\", \"similar\": \"luminous\"},\n",
    "    {\"word\": \"cold\", \"similar\": \"chilly\"},\n",
    "    {\"word\": \"smart\", \"similar\": \"intelligent\"},\n",
    "    {\"word\": \"angry\", \"similar\": \"furious\"},\n",
    "    {\"word\": \"beautiful\", \"similar\": \"gorgeous\"},\n",
    "    {\"word\": \"strong\", \"similar\": \"powerful\"},\n",
    "    {\"word\": \"sad\", \"similar\": \"unhappy\"},\n",
    "    {\"word\": \"brave\", \"similar\": \"courageous\"},\n",
    "    {\"word\": \"funny\", \"similar\": \"humorous\"},\n",
    "    {\"word\": \"calm\", \"similar\": \"peaceful\"},\n",
    "    {\"word\": \"thin\", \"similar\": \"slim\"},\n",
    "    {\"word\": \"tired\", \"similar\": \"exhausted\"},\n",
    "    {\"word\": \"rich\", \"similar\": \"wealthy\"},\n",
    "    {\"word\": \"friendly\", \"similar\": \"amiable\"},\n",
    "    {\"word\": \"hot\", \"similar\": \"warm\"},\n",
    "    {\"word\": \"strong\", \"similar\": \"robust\"},\n",
    "    {\"word\": \"clean\", \"similar\": \"pristine\"},\n",
    "    {\"word\": \"old\", \"similar\": \"ancient\"},\n",
    "    {\"word\": \"new\", \"similar\": \"modern\"},\n",
    "    {\"word\": \"hungry\", \"similar\": \"famished\"},\n",
    "    {\"word\": \"quiet\", \"similar\": \"silent\"},\n",
    "    {\"word\": \"dark\", \"similar\": \"dim\"},\n",
    "    {\"word\": \"happy\", \"similar\": \"content\"},\n",
    "    {\"word\": \"careful\", \"similar\": \"cautious\"},\n",
    "    {\"word\": \"confident\", \"similar\": \"self-assured\"},\n",
    "    {\"word\": \"creative\", \"similar\": \"inventive\"},\n",
    "    {\"word\": \"curious\", \"similar\": \"inquisitive\"},\n",
    "    {\"word\": \"dangerous\", \"similar\": \"hazardous\"},\n",
    "    {\"word\": \"delicious\", \"similar\": \"tasty\"},\n",
    "    {\"word\": \"easy\", \"similar\": \"simple\"},\n",
    "    {\"word\": \"effective\", \"similar\": \"efficient\"},\n",
    "    {\"word\": \"expensive\", \"similar\": \"costly\"},\n",
    "    {\"word\": \"famous\", \"similar\": \"well-known\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "User: {word}\n",
    "Response: {similar}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt_input_variables = ['word','similar']\n",
    "\n",
    "example_prompt_template = PromptTemplate(\n",
    "    input_variables=example_prompt_input_variables,\n",
    "    template=example_formatter_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# I would be using Cohere Embeddings\n",
    "# COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "# cohere_embeddings = CohereEmbeddings(\n",
    "#     model=\"embed-english-v2.0\",\n",
    "#     cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEndpointEmbeddings()\n",
    "\n",
    "# Create Deep Lake dataset\n",
    "ACTIVELOOP_TOKEN = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "my_activeloop_org_id = \"danllm\"\n",
    "my_activeloop_dataset_name = \"semantic_similarity_example_selector_fewshot_selector\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 36 embeddings in 1 batches of size 36:: 100%|██████████| 1/1 [00:03<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='./deeplake/', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (36, 1)     str     None   \n",
      " metadata     json      (36, 1)     str     None   \n",
      " embedding  embedding  (36, 768)  float32   None   \n",
      "    id        text      (36, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate SemanticSimilarityExampleSelector using the examples\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, embeddings, db,k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the FewShot prompt template\n",
    "\n",
    "# prefix\n",
    "prefix = \"\"\"You are a highly skilled English teacher with a PhD.\n",
    "The following a similarity between words.\n",
    "Carefully give the most close synonym to the word when prompted.\n",
    "Here are some examples: \n",
    "\"\"\"\n",
    "\n",
    "# suffix\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "Response:\"\"\"\n",
    "\n",
    "# fewshot prompt variables\n",
    "few_shot_input_variables = ['query']\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt_template,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=few_shot_input_variables,\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "print(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query:\n",
      "categorically evil\n",
      "\n",
      "AI Response:\n",
      "utterly wicked\n"
     ]
    }
   ],
   "source": [
    "user_input_query = input(\"Type here > \")\n",
    "\n",
    "input_data = {\"query\": user_input_query}\n",
    "\n",
    "# Running the Chain\n",
    "llm_chain = few_shot_prompt_template | llm\n",
    "response = llm_chain.invoke(input_data)\n",
    "\n",
    "# Display output\n",
    "print(f\"User query:\\n{input_data['query']}\\n\")\n",
    "print(f\"AI Response:\\n{response.strip()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

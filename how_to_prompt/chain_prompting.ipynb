{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceEndpoint\n",
    "# the new way\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate,FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Provide the filename as a string\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"max_new_tokens\": 1000, # Maximum tokens to generate\n",
    "    \"max_length\": 5000, # Maximum length of input + output\n",
    "    \"temperature\": 0.1, # Controls randomness of output\n",
    "    \"timeout\": 6000,\n",
    "    # \"task\":'conversational',\n",
    "}\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
    "    # you specify the task or not\n",
    "    # You can also specify the task in the model_kwargs or within here\n",
    "    # task = 'conversational',\n",
    "    **model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chain Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain Prompting refers to the practice of chaining consecutive prompts, where the output of a previous prompt becomes the input of the successive prompt.\n",
    "\n",
    "To use chain prompting with LangChain, you could:\n",
    "\n",
    "- Extract relevant information from the generated response.\n",
    "- Use the extracted information to create a new prompt that builds upon the previous response.\n",
    "- Repeat steps as needed until the desired output is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question template\n",
    "prompt_template_question = \"\"\"\n",
    "You are an expert journalist that has \n",
    "written countless articles and journals for major newspaper and blog publishers.\n",
    "Kindly provide ONLY the name(s) of the person(s) started {company} ? and nothing else.\n",
    "ONLY PROVIDE THE NAMES\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_question_input_variables = ['company']\n",
    "\n",
    "prompt_question = PromptTemplate(\n",
    "    template=prompt_template_question,\n",
    "    input_variables=prompt_question_input_variables\n",
    ")\n",
    "\n",
    "\n",
    "# Fact template\n",
    "prompt_template_fact = \"\"\"\n",
    "Provide a brief article of how the {person} started the company. Provide a title for the article\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_fact_input_variables = ['person']\n",
    "prompt_fact = PromptTemplate(\n",
    "    template=prompt_template_fact,\n",
    "    input_variables=prompt_fact_input_variables\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates and Paul Allen\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Who founded > \")\n",
    "\n",
    "input_data = {\"company\": user_input}\n",
    "\n",
    "llm_chain_question = prompt_question | llm\n",
    "\n",
    "response_question = llm_chain_question.invoke(input_data)\n",
    "\n",
    "# Extract the person's name from the response\n",
    "person = response_question.strip()\n",
    "print(person) # checking intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data for the second prompt\n",
    "fact_input_data = {\"person\":person}\n",
    "\n",
    "llm_chain_fact = prompt_fact | llm\n",
    "\n",
    "response_fact = llm_chain_fact.invoke(fact_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person Name(s): Bill Gates and Paul Allen\n",
      "\n",
      "Facts:\n",
      "Title: \"The Genesis of a Tech Titan: The Unlikely Partnership of Bill Gates and Paul Allen that Launched Microsoft\"\n",
      "\n",
      "In the annals of tech history, few partnerships have left an indelible mark like that of Bill Gates and Paul Allen. The duo, who met in their teenage years, would go on to create one of the most influential companies in the world: Microsoft.\n",
      "\n",
      "Their story began in 1970, at the prestigious Lakeside School in Seattle, Washington. Both Gates and Allen were computer enthusiasts, spending countless hours in the school's computer lab. It was here that they first crossed paths, their shared passion for computers forming the foundation of their future collaboration.\n",
      "\n",
      "After graduating from college, Gates moved to New Mexico to work for Honeywell, while Allen went to work for Boeing. However, their shared dream of creating software for personal computers was too strong to ignore. In 1975, they decided to leave their respective jobs and start a company.\n",
      "\n",
      "Their initial venture was called Traf-O-Data, a company that aimed to create traffic counters for the government. Although the business didn't take off, it provided them with valuable experience and introduced them to the world of entrepreneurship.\n",
      "\n",
      "In 1976, they shifted their focus to microcomputers, a nascent industry at the time. They saw the potential in the Altair 8800, a DIY personal computer kit, and decided to create a BASIC interpreter for it. Gates wrote the code, and Allen handled the hardware. In March 1975, they demonstrated their software at the first West Coast Computer Faire, impressing the audience and the Altair's creator, Ed Roberts.\n",
      "\n",
      "The success of their demonstration led to a contract with MITS, the company that manufactured the Altair. Gates and Allen officially registered their company as Micro-Soft (later changed to Microsoft) in April 1975. Their first product, the Altair BASIC, was a hit, and Microsoft was on its way to becoming a tech giant.\n",
      "\n",
      "Over the years, Microsoft expanded its product line, introducing operating systems like MS-DOS and Windows, and software like Office Suite. Today, Microsoft is a household name, synonymous with personal computing. The partnership between Bill Gates and Paul Allen, two teenage computer enthusiasts from Seattle, has left an indelible mark on the tech industry. Their story serves as a testament to the power of passion, perseverance, and the pursuit of innovation.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Person Name(s): {person}\\n\")\n",
    "print(f\"Facts:\\n{response_fact.strip()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
